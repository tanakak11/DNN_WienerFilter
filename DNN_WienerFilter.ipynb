{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_WienerFilter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMyRuyzgMj/H9qIT4IvwEV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanakak11/DNN_WienerFilter/blob/main/DNN_WienerFilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H8S1Wdue5Lj"
      },
      "source": [
        "!pip install torch>=1.2.0\n",
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvdboCV4UIyJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio import datasets, transforms\n",
        "from torchaudio.datasets.utils import(\n",
        "    download_url,\n",
        "    extract_archive,\n",
        "    walk_files,\n",
        ")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "from typing import Tuple\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import wave as wave\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S54CF6XBeRei"
      },
      "source": [
        "# drive.mount('/content/drive')\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9-Fd55VEIr"
      },
      "source": [
        "# Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, n_in, n_h, n_out):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = nn.Linear(n_in, n_h)\n",
        "    self.l2 = nn.Linear(n_h, n_h)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.l3 = nn.Linear(n_h, n_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    h = F.relu(self.l1(x))\n",
        "    h = F.relu(self.l2(h))\n",
        "    h = self.dropout2(h)\n",
        "    h = torch.sigmoid(self.l3(h))\n",
        "    \"\"\"\n",
        "    h = torch.sigmoid(self.l1(x))\n",
        "    h = torch.sigmoid(self.l2(h))\n",
        "    h = self.dropout2(h)\n",
        "    h = self.l3(h)\n",
        "\n",
        "    return h"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYyaMOH1z0Ru"
      },
      "source": [
        "# 出力先の指定\n",
        "\n",
        "base_path = \"/content/drive/My Drive/\"\n",
        "output_filename = \"Output_WF_-5-10dB_20ep\"\n",
        "output_base_path = os.path.join(base_path, output_filename)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhj4AymPSrtb"
      },
      "source": [
        "# DataLoader\n",
        "\n",
        "URL = \"train_16000\"\n",
        "\n",
        "def load_timit_item(fileid: str,\n",
        "                    path: str) -> Tuple[Tensor, Tensor]:\n",
        "\n",
        "    filter_path = os.path.join(path, fileid, \"filter.cpickle\")    # for WF\n",
        "    mixed_path = os.path.join(path, fileid,  \"input_data.cpickle\")  # for WF\n",
        "\n",
        "    \n",
        "    # Wiener-Filterのフィルタ係数\n",
        "    \n",
        "    with open(filter_path, mode='rb') as f:     # for WF\n",
        "      sn_ratio = pickle.load(f)\n",
        "\n",
        "    with open(mixed_path, mode='rb') as f:\n",
        "      data = pickle.load(f)\n",
        "\n",
        "    return (\n",
        "        data,\n",
        "        sn_ratio\n",
        "    )\n",
        "\n",
        "class TIMIT16000(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "               root: str,\n",
        "               url: str = URL,\n",
        "               download: bool = False) -> None:\n",
        "\n",
        "      if url in[\n",
        "            \"train_16000\",\n",
        "            \"train_16000_0.0dB\",\n",
        "            \"train_16000_10.0dB\",\n",
        "            \"train_16000_0-5dB\",\n",
        "            \"train_16000_-1-4dB\",\n",
        "            \"train_16000_-5-10dB\",\n",
        "            \"test_16000\",\n",
        "            \"test_16000_0.0dB\",\n",
        "            \"test_16000_10.0dB\",\n",
        "            \"test_16000_0-5dB\",\n",
        "            \"test_16000_-1-4dB\",\n",
        "            \"test_16000_-5-10dB\",\n",
        "            \"demo_data\"\n",
        "      ]:\n",
        "\n",
        "        base_url = \"/content/drive/My Drive/\"\n",
        "        append_url = os.path.join(base_url, url)\n",
        "\n",
        "      self._path = append_url\n",
        "\n",
        "      dir_path = os.path.join(self._path, \"*\" + os.sep)\n",
        "\n",
        "      self._dir_list = glob.glob(dir_path, recursive=True)\n",
        "\n",
        "      if url in [\n",
        "                 \"test_16000\",\n",
        "                 \"test_16000_0.0dB\",\n",
        "                 \"test_16000_10.0dB\",\n",
        "                 \"test_16000_0-5dB\",\n",
        "                 \"test_16000_-1-4dB\",\n",
        "                 \"test_16000_-5-10dB\",\n",
        "                 \"demo_data\"\n",
        "      ]:\n",
        "        self._dir_list = self._dir_list[:200]\n",
        "      \n",
        "      print(len(self._dir_list))\n",
        "      print(self._dir_list)\n",
        "\n",
        "      if url in [\n",
        "                 \"test_16000\",\n",
        "                 \"test_16000_0.0dB\",\n",
        "                 \"test_16000_10.0dB\",\n",
        "                 \"test_16000_0-5dB\",\n",
        "                 \"test_16000_-1-4dB\",\n",
        "                 \"test_16000_-5-10dB\",\n",
        "                 \"demo_data\"\n",
        "      ]:\n",
        "        list_path = os.path.join(base_path, output_filename, \"list.txt\")\n",
        "\n",
        "        with open(list_path, mode='w') as f:\n",
        "          f.write('\\n'.join(self._dir_list))\n",
        "        \n",
        "        print(\"done\")\n",
        "\n",
        "\n",
        "  def __getitem__(self, n: int) -> Tuple[Tensor, Tensor]:\n",
        "    fileid = self._dir_list[n]\n",
        "\n",
        "    return load_timit_item(fileid, self._path)\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self._dir_list)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g9_Sd9ENna4"
      },
      "source": [
        "# 正則化関数\n",
        "\n",
        "def L1_loss(y, label):\n",
        "  loss = torch.reduce_mean(torch.abs(y - label))\n",
        "  return loss\n",
        "\n",
        "def L2_loss(y, label):\n",
        "  loss = torch.mean((torch.square(torch.abs(y - label))))\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON5bwMr3WDPw"
      },
      "source": [
        "# DatasetとModelの宣言\n",
        "\n",
        "min_len = 59\n",
        "\n",
        "epoch = 20\n",
        "batchsize = 8\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "wf_train_data = TIMIT16000('data',\n",
        "                           url = \"train_16000_-5-10dB\",\n",
        "                           download=True)\n",
        "\n",
        "wf_test_data = TIMIT16000('data',\n",
        "                          url = \"test_16000_0.0dB\",\n",
        "                          download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(wf_train_data,\n",
        "                                           batch_size=batchsize,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(wf_test_data,\n",
        "                                          batch_size=batchsize,\n",
        "                                          shuffle=False)\n",
        "\n",
        "model = Net(1026, 2052, 513).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.MSELoss()  # 基本的に使わない"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRivh5q81Ql"
      },
      "source": [
        "# 学習済みのモデルの読み込み(必要に応じて)\r\n",
        "\r\n",
        "model_path = os.path.join(output_base_path, \"learned_model_20ep.pth\")\r\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YALhsz6Zfq-_"
      },
      "source": [
        "model.train()\n",
        "for ep in range(1, epoch+1):\n",
        "  tot_loss = 0.0\n",
        "\n",
        "  for batch_idx, (data, sn_ratio) in enumerate(train_loader):\n",
        "\n",
        "    input = data[0, :, :]\n",
        "    label = sn_ratio[0, :, :]\n",
        "\n",
        "    for i in range(1, batchsize):\n",
        "      input = torch.cat((input, data[i, :, :]), 1)\n",
        "      label = torch.cat((label, sn_ratio[i, :, :]), 1)\n",
        "\n",
        "    input = torch.transpose(input, 0, 1)\n",
        "    label = torch.transpose(label, 0, 1)\n",
        "\n",
        "    input, label = input.to(device), label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input)\n",
        "\n",
        "    # loss = criterion(output, label)\n",
        "    loss = L2_loss(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tot_loss += loss.item()\n",
        "\n",
        "  print('Epoch: {:2d}, Average loss: {:.6f}'.format(ep, tot_loss / ((len(train_loader)) * min_len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBbdkWd3vKXw"
      },
      "source": [
        "# 学習済みモデルの保存\n",
        "\n",
        "model_path = os.path.join(output_base_path, \"learned_model_20ep.pth\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlG-th9rgxzJ"
      },
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (data, sn_ratio) in enumerate(test_loader):\n",
        "\n",
        "    input = data[0, :, :]\n",
        "    label = sn_ratio[0, :, :]\n",
        "\n",
        "    for j in range(1, batchsize):\n",
        "      input = torch.cat((input, data[j, :, :]), 1)\n",
        "      label = torch.cat((label, sn_ratio[j, :, :]), 1)\n",
        "\n",
        "    input = torch.transpose(input, 0, 1)\n",
        "    label = torch.transpose(label, 0, 1)\n",
        "\n",
        "    input, label = input.to(device), label.to(device)\n",
        "\n",
        "    output = model(input)\n",
        "\n",
        "    # test_loss += criterion(output, label)\n",
        "    test_loss += L2_loss(output, sn_ratio)\n",
        "\n",
        "    output_path = os.path.join(output_base_path, \"{:04d}\".format(i))\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "    output_filter_path = os.path.join(output_path, \"filter.cpickle\")\n",
        "\n",
        "    with open(output_filter_path, mode='wb') as f:\n",
        "      pickle.dump(output, f)\n",
        "\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b2-P7-Qa6E1"
      },
      "source": [
        "# デモ動画のロード\n",
        "\n",
        "wf_demo_data = TIMIT16000('data',\n",
        "                          url = \"demo_data\",\n",
        "                          download=True)\n",
        "\n",
        "demo_loader = torch.utils.data.DataLoader(wf_demo_data,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR9_TpEbHIaz"
      },
      "source": [
        "# Demo\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (input, label) in enumerate(demo_loader):\n",
        "    print(np.shape(input))\n",
        "    print(np.shape(label))\n",
        "\n",
        "    input = torch.transpose(input, 1, 2)\n",
        "    label = torch.transpose(label, 1, 2)\n",
        "\n",
        "    print(np.shape(input))\n",
        "    print(np.shape(label))\n",
        "\n",
        "    input, label = input.to(device), label.to(device)\n",
        "\n",
        "    output = model(input)\n",
        "    # test_loss += L2_loss(output, sn_ratio)\n",
        "\n",
        "    output_path = os.path.join(output_base_path, \"{:04d}\".format(i+100))\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "    output_filter_path = os.path.join(output_path, \"filter.cpickle\")\n",
        "\n",
        "    with open(output_filter_path, mode='wb') as f:\n",
        "      pickle.dump(output, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}